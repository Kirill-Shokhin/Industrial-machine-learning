{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "В следующей ячейке написал код по обучению модели машинного обучения для классификации Ирисов.\n",
    "Необходимо реализовать веб-сервис на Flask, который бы позволял использовать эту модель для классификации через сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как вы реализуете свой веб-сервис, достаточно будет его запустить и нажать кнопку \"Отправить решение\". После нажатия автоматически запустится скрипт `check-server.py`, который создаст файл `result.json`. \n",
    "\n",
    "Сам скрипт можно использовать для проверки корректности своего решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pickle.dumps(clf)\n",
    "\n",
    "with open('fmeter-model.pickle', 'wb') as f:\n",
    "    f.write(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server.py\n",
    "from flask import Flask, request\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "app = Flask(__name__)  # Основной объект приложения Flask\n",
    "\n",
    "\n",
    "def load_model(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        model = pickle.loads(raw_data)\n",
    "    return model\n",
    "\n",
    "model = load_model('fmeter-model.pickle')\n",
    "\n",
    "@app.route('/')\n",
    "def hello():\n",
    "    return \"Hello, from Flask\"\n",
    "\n",
    "@app.route('/iris', methods=[\"GET\", \"POST\"])\n",
    "def iris_handler():\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json(force=True) \n",
    "        result = model.predict([data['iris']])[0]  \n",
    "        response = {\n",
    "            \"result\": int(result)\n",
    "        }\n",
    "        return json.dumps(response)\n",
    "    else:\n",
    "        return \"You should use only POST query\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(\"0.0.0.0\", 8000)  # Запускаем сервер на 8000 порту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! launch-server.sh server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\r\n",
      "\r\n",
      "import requests\r\n",
      "import json\r\n",
      "\r\n",
      "questions = [\r\n",
      "    [4.6, 3.1, 1.5, 0.2],\r\n",
      "    [5.2, 2.7, 3.9, 1.4],\r\n",
      "    [6.9, 3.1, 5.1, 2.3]\r\n",
      "]\r\n",
      "\r\n",
      "result = []\r\n",
      "for q in questions:\r\n",
      "    data = {\r\n",
      "        'iris': q\r\n",
      "    }\r\n",
      "\r\n",
      "    r = requests.post(\"http://localhost:8000/iris\", json=data)\r\n",
      "    result.append(r.json()['result'])\r\n",
      "\r\n",
      "with open('/home/jovyan/work/result.json', 'w') as f:\r\n",
      "    f.write(json.dumps(result, indent=4))"
     ]
    }
   ],
   "source": [
    "! cat $(which check-server.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"server\" (lazy loading)\r\n",
      " * Environment: production\r\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\r\n",
      "   Use a production WSGI server instead.\r\n",
      " * Debug mode: off\r\n",
      " * Running on http://0.0.0.0:8000/ (Press CTRL+C to quit)\r\n",
      "127.0.0.1 - - [20/Aug/2021 18:23:26] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [20/Aug/2021 18:23:29] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [20/Aug/2021 18:23:30] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [20/Aug/2021 18:23:48] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [20/Aug/2021 18:23:48] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [20/Aug/2021 18:23:48] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n"
     ]
    }
   ],
   "source": [
    "! cat log.txt"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "4-sync-arch-task-72e120123"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
