{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача \n",
    "\n",
    "В следующей ячейке написал код по обучению модели машинного обучения для классификации Ирисов.\n",
    "Необходимо реализовать веб-сервис на Flask и обработчик на Celery таким образом, чтобы получившаяся система позволяла использовать эту модель для классификации через сеть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как вы реализуете свой веб-сервис, достаточно будет его запустить и нажать кнопку \"Отправить решение\". После нажатия автоматически запустится скрипт `check-server.py`, который создаст файл `result.json`. \n",
    "\n",
    "Сам скрипт можно использовать для проверки корректности своего решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pickle.dumps(clf)\n",
    "\n",
    "with open('fmeter-model.pickle', 'wb') as f:\n",
    "    f.write(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server.py\n",
    "from celery import Celery\n",
    "from celery.result import AsyncResult\n",
    "import time\n",
    "from flask import Flask, request\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "celery_app = Celery('server', backend='redis://localhost', broker='redis://localhost')  # и брокер и база - redis\n",
    "app = Flask(__name__)  # Основной объект приложения Flask\n",
    "\n",
    "\n",
    "def load_model(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        model = pickle.loads(raw_data)\n",
    "    return model\n",
    "\n",
    "model = load_model('fmeter-model.pickle')\n",
    "\n",
    "@celery_app.task\n",
    "def predict(data_iris):\n",
    "    result = int(model.predict([data_iris])[0])\n",
    "    return result\n",
    "\n",
    "@app.route('/iris', methods=[\"GET\", \"POST\"])\n",
    "def predict_handler():\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json(force=True) \n",
    "        task = predict.delay(data['iris']) \n",
    "        response = {\n",
    "            \"task_id\": task.id\n",
    "        }\n",
    "        return json.dumps(response)\n",
    "    \n",
    "@app.route('/iris/<task_id>')\n",
    "def predict_check_handler(task_id):\n",
    "    task = AsyncResult(task_id, app=celery_app)\n",
    "    if task.ready():\n",
    "        response = {\n",
    "            \"status\": \"DONE\",\n",
    "            \"result\": task.result\n",
    "        }\n",
    "    else:\n",
    "        response = {\n",
    "            \"status\": \"IN_PROGRESS\"\n",
    "        }\n",
    "    return json.dumps(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(\"0.0.0.0\", 8000)  # Запускаем сервер на 8000 порту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! start-worker.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\r\n"
     ]
    }
   ],
   "source": [
    "! launch-server.sh server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\r\n",
      "\r\n",
      "import requests\r\n",
      "import json\r\n",
      "import time\r\n",
      "\r\n",
      "questions = [\r\n",
      "    [4.6, 3.1, 1.5, 0.2],\r\n",
      "    [5.2, 2.7, 3.9, 1.4],\r\n",
      "    [6.9, 3.1, 5.1, 2.3]\r\n",
      "]\r\n",
      "\r\n",
      "result = []\r\n",
      "for q in questions:\r\n",
      "    data = {\r\n",
      "        'iris': q\r\n",
      "    }\r\n",
      "\r\n",
      "    response = requests.post(\"http://localhost:8000/iris\", json=data)\r\n",
      "    task_id = response.json()['task_id']\r\n",
      "    status = \"IN_PROGRESS\"\r\n",
      "    while status != \"DONE\":\r\n",
      "        time.sleep(2.0)\r\n",
      "        r = requests.get('http://localhost:8000/iris/{}'.format(task_id))\r\n",
      "        status = r.json()['status']\r\n",
      "\r\n",
      "    result.append(r.json()['result'])\r\n",
      "\r\n",
      "with open('/home/jovyan/work/result.json', 'w') as f:\r\n",
      "    f.write(json.dumps(result, indent=4))"
     ]
    }
   ],
   "source": [
    "! cat $(which check-server.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"server\" (lazy loading)\r\n",
      " * Environment: production\r\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\r\n",
      "   Use a production WSGI server instead.\r\n",
      " * Debug mode: off\r\n",
      " * Running on http://0.0.0.0:8000/ (Press CTRL+C to quit)\r\n",
      "127.0.0.1 - - [27/Aug/2021 06:56:42] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [27/Aug/2021 06:56:44] \"\u001b[37mGET /iris/ad8c3716-4f44-40cf-b347-c69ae56aa021 HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [27/Aug/2021 06:56:44] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [27/Aug/2021 06:56:46] \"\u001b[37mGET /iris/92056716-cbf3-4759-9d9c-b5cb9ed858a9 HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [27/Aug/2021 06:56:46] \"\u001b[37mPOST /iris HTTP/1.1\u001b[0m\" 200 -\r\n",
      "127.0.0.1 - - [27/Aug/2021 06:56:48] \"\u001b[37mGET /iris/09f8f64e-bff6-4ab4-ba40-5b01e734a72d HTTP/1.1\u001b[0m\" 200 -\r\n"
     ]
    }
   ],
   "source": [
    "! cat log.txt"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "5-async-arch-task-799220123"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
