{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"../cluster\" style=\"font-size:20px\">All Applications (YARN)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "В лекциях мы обсуждали меру Жаккара и то, как ее эффективно считать на MapReduce.\n",
    "\n",
    "Вам предлагается посчитать меру Жаккара на Spark для поиска похожих исполнителей во всем наборе данных и ответить на следующие вопросы:\n",
    "1. **Сколько исполнителей остаются в рассмотрении после применения всех фильтров из описания задания?**\n",
    "2. **Для скольких пар исполнителей удалось насчитать ненулевую похожесть по Жаккару? Здесь учитываются всевозможные пары (a, b) и (b, a), а также (a, a), для проверки корректности.**\n",
    "3. **Найдите 5 самых похожих исполнителей на \"Maroon 5\" по посчитанной мере Жаккара. В результат запишите имена 5 исполнителей отличных от \"Maroon 5\".**\n",
    "\n",
    "Несколько напутственных слов:\n",
    "- Используйте данные, загруженные в разделе <a href=\"#Загружаем-данные\">Загружаем данные</a>.\n",
    "- Пользователи, прослушавшие $N$ исполнителей внесут вклад в похожесть $N^2$ пар артистов. Поэтому редкие очень активные пользователи будут сильно замедлять наш алгоритм. Для таких пользователей на практике берут подмножество прослушиваний, например, 1000. Мы поступим проще и будем учитывать только прослушивания, где $plays > 2$, таким образом оставим только наиболее уверенные предпочтения пользователя.\n",
    "- Чтобы похожести были более уверенными, будем считать их только для тех исполнителей, которых прослушали строго больше 50 человек (с учетом предыдущего фильтра по прослушиваниям).\n",
    "- Для отладки алгоритма на меньшем объеме данных можно использовать трансформацию <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sample\">events.sample(False, 0.01)</a>, чтобы не ждать долго отладочных запусков.\n",
    "- Можно считать, что данные об исполнителях (например, их популярность) поместятся в памяти каждой машины. Просто нет так много исполнителей в мире, чтобы не поместиться.\n",
    "- Если какой-то шаг выполняется очень долго, можно увеличить степень параллелизма, например, \n",
    "<a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupByKey\">groupByKey(numPartitions=100)</a>, чтобы увидеть более гранулярный прогресс выполнения.\n",
    "- Иногда посчитанный результат имеет смысл сохранить в HDFS, чтобы не пересчитывать его заново каждый раз, когда он нужен.\n",
    "- При работе с большими данными требуется терпение, авторское решение работает около 10 минут.\n",
    "- Эту задачу можно решить и на Spark SQL, если вам он нравится больше.\n",
    "\n",
    "Решение сохраните в файл `result.json`. Пример содержимого файла:\n",
    "```json\n",
    "{\n",
    "    \"q1\": 123,\n",
    "    \"q2\": 456,\n",
    "    \"q3\": [\n",
    "        \"artistName1\",\n",
    "        \"artistName2\",\n",
    "        \"artistName3\",\n",
    "        \"artistName4\",\n",
    "        \"artistName5\"\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/yandex_music/README.txt': File exists\n",
      "copyFromLocal: `/yandex_music/artists.jsonl': File exists\n",
      "copyFromLocal: `/yandex_music/events.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -copyFromLocal yandex_music /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   1 jovyan supergroup        254 2021-08-16 09:59 /yandex_music/README.txt\r\n",
      "-rw-r--r--   1 jovyan supergroup      3.7 M 2021-08-16 09:59 /yandex_music/artists.jsonl\r\n",
      "-rw-r--r--   1 jovyan supergroup     47.6 M 2021-08-16 09:59 /yandex_music/events.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls -h /yandex_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='jupyter')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistId</th>\n",
       "      <th>artistName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mack Gordon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kenny Dorham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Max Roach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Francis Rossi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Status Quo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistId     artistName\n",
       "0         0    Mack Gordon\n",
       "1         1   Kenny Dorham\n",
       "2         2      Max Roach\n",
       "3         3  Francis Rossi\n",
       "4         4     Status Quo"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = se.read.json(\"hdfs:///yandex_music/artists.jsonl\")\n",
    "artists.registerTempTable(\"artists\")\n",
    "artists.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>artistId</th>\n",
       "      <th>plays</th>\n",
       "      <th>skips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>710</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>815</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  artistId  plays  skips\n",
       "0       0       335      1      0\n",
       "1       0       708      1      0\n",
       "2       0       710      2      1\n",
       "3       0       815      1      1\n",
       "4       0       880      1      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = se.read.csv(\"hdfs:///yandex_music/events.csv\", header=True, \n",
    "                     schema='userId bigint, artistId bigint, plays INT, skips INT')\n",
    "events.registerTempTable(\"events\")\n",
    "events.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|userId|cnt|\n",
      "+------+---+\n",
      "|  4689|644|\n",
      "|  3121|577|\n",
      "|  4575|572|\n",
      "|  2266|519|\n",
      "|  4217|512|\n",
      "+------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# на каждого пользователя приходится меньше 1000 исполнителей с plays > 2\n",
    "se.sql(\n",
    "\"\"\"\n",
    "select \n",
    "    userId,\n",
    "    count(*) as cnt\n",
    "from events\n",
    "where plays > 2\n",
    "group by userId\n",
    "order by cnt desc\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ТУТ ВАШ КОД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = se.sql(\n",
    "\"\"\"\n",
    "select userId, artistId\n",
    "from(\n",
    "    select userId, events.artistId, plays, popularity\n",
    "    from   (\n",
    "            select *\n",
    "            from(\n",
    "                select artistId, count(*) as popularity\n",
    "                from(\n",
    "                    select distinct userId, artistId\n",
    "                    from \n",
    "                        events \n",
    "                    where plays > 2\n",
    "                    )\n",
    "                group by artistId\n",
    "                )\n",
    "            where popularity > 50\n",
    "             )as s join events on s.artistId = events.artistId\n",
    "    where plays > 2\n",
    "    order by userId, artistId\n",
    "    )\n",
    "group by userId, artistId\n",
    "order by userId, artistId\n",
    "\"\"\")\n",
    "# table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498589"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.cache()\n",
    "table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df = table.groupBy('userId').agg(F.collect_list(\"artistId\").alias('pairs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_1', '1_2', '1_3', '2_1', '2_2', '2_3', '3_1', '3_2', '3_3']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(list_):\n",
    "    lis = []\n",
    "    for i in list_:\n",
    "        for j in list_:\n",
    "#             if j>=i:\n",
    "                lis.append('{}_{}'.format(i, j))\n",
    "    return lis\n",
    "f([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "udf_f = udf(f, ArrayType(StringType()))\n",
    "pairs = df.withColumn(\"pairs\", udf_f(col(\"pairs\"))).select('pairs')\n",
    "big_col = pairs.select(explode('pairs'))\n",
    "cnt_col = big_col.groupBy('col').count().sort(desc('count'))\n",
    "split = cnt_col.withColumn('A', split(cnt_col['col'], '_').getItem(0)) \\\n",
    "       .withColumn('B', split(cnt_col['col'], '_').getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listenings = table.groupby('artistId').count().sort(desc('count')).toPandas().set_index('artistId')\n",
    "def artist_to_listenings(id_):\n",
    "    return int(listenings.loc[int(id_)].values[0])\n",
    "\n",
    "AtoL = udf(artist_to_listenings, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 129 ms, sys: 33.8 ms, total: 163 ms\n",
      "Wall time: 15min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = split.withColumn(\"jaccard\", (col(\"count\")/(AtoL(col(\"A\"))+AtoL(col(\"B\"))-col(\"count\")))).drop('col')\n",
    "result.cache()\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6838579"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('jaccard').filter('jaccard is not null').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|artistId|artistName|\n",
      "+--------+----------+\n",
      "|   14803|  Maroon 5|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists.select('*').where('artistName = \"Maroon 5\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-------------------+\n",
      "|count|    A|    B|            jaccard|\n",
      "+-----+-----+-----+-------------------+\n",
      "|  919|14803|14803|                1.0|\n",
      "|  489|14803| 3568| 0.3319755600814664|\n",
      "|  610|14803| 3629|0.31266017426960535|\n",
      "|  537|14803|  259|0.29184782608695653|\n",
      "|  318|14803|22629| 0.2867448151487827|\n",
      "|  464|14803|59783| 0.2858903265557609|\n",
      "+-----+-----+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"*\").where('A = 14803').sort(desc('jaccard')).limit(6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|artistId|   artistName|\n",
      "+--------+-------------+\n",
      "|   59783|Calvin Harris|\n",
      "+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists.select('*').where('artistId = 59783').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting result.json\n"
     ]
    }
   ],
   "source": [
    "%%file result.json\n",
    "{\n",
    "    \"q1\": 2889,\n",
    "    \"q2\": 6838579,\n",
    "    \"q3\": [\n",
    "        \"OneRepublic\",\n",
    "        \"Sia\",\n",
    "        \"David Guetta\",\n",
    "        \"Bruno Mars\",\n",
    "        \"Calvin Harris\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"q1\": 2889,\r\n",
      "    \"q2\": 6838579,\r\n",
      "    \"q3\": [\r\n",
      "        \"OneRepublic\",\r\n",
      "        \"Sia\",\r\n",
      "        \"David Guetta\",\r\n",
      "        \"Bruno Mars\",\r\n",
      "        \"Calvin Harris\"\r\n",
      "    ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# останавливаем Spark (и YARN приложение)\n",
    "# sc.stop()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "lab-task-5a2a5e"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
